"""
ëŒ€ì‹œë³´ë“œ ì„œë¹„ìŠ¤

ëŒ€ì‹œë³´ë“œ ë¶„ì„ ë° ìš”ì•½ì„ ìœ„í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""

import csv
import json
import logging
import time
from datetime import datetime, timedelta, timezone
from io import StringIO
from typing import Any, Dict, List, Optional, cast
from uuid import UUID, uuid4

import psutil
from sqlalchemy import and_, or_, select, text
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.sql.functions import count

from core.database import get_async_session
from models.calendar import Calendar, Event
from models.project import Project, ProjectMember
from models.task import Task, TaskAssignment
from models.user import User, UserActivityLog

logger = logging.getLogger(__name__)


# ============================================================================
# ëŒ€ì‹œë³´ë“œ ì„œë¹„ìŠ¤ ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤
# ============================================================================


class DashboardServiceError(Exception):
    """ëŒ€ì‹œë³´ë“œ ì„œë¹„ìŠ¤ ê¸°ë³¸ ì˜ˆì™¸"""

    def __init__(
        self,
        message: str,
        code: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None,
    ):
        self.message = message
        self.code = code or "DASHBOARD_ERROR"
        self.details = details or {}
        super().__init__(self.message)

    def __str__(self):
        return self.message


class DashboardDataNotFoundError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"""

    def __init__(
        self,
        message: str,
        resource_type: Optional[str] = None,
        resource_id: Optional[str] = None,
    ):
        super().__init__(
            message,
            code="DASHBOARD_DATA_NOT_FOUND",
            details={"resource_type": resource_type, "resource_id": resource_id},
        )


class DashboardPermissionError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ"""

    def __init__(
        self,
        message: str,
        required_permission: Optional[str] = None,
        user_id: Optional[str] = None,
    ):
        super().__init__(
            message,
            code="DASHBOARD_PERMISSION_DENIED",
            details={"required_permission": required_permission, "user_id": user_id},
        )


class DashboardValidationError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨"""

    def __init__(
        self, message: str, field: Optional[str] = None, value: Optional[Any] = None
    ):
        super().__init__(
            message,
            code="DASHBOARD_VALIDATION_ERROR",
            details={
                "field": field,
                "value": str(value) if value is not None else None,
            },
        )


class DashboardExportError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨"""

    def __init__(
        self,
        message: str,
        export_format: Optional[str] = None,
        export_id: Optional[str] = None,
    ):
        super().__init__(
            message,
            code="DASHBOARD_EXPORT_ERROR",
            details={"export_format": export_format, "export_id": export_id},
        )


class DashboardCacheError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ìºì‹œ ê´€ë ¨ ì˜¤ë¥˜"""

    def __init__(
        self,
        message: str,
        cache_key: Optional[str] = None,
        operation: Optional[str] = None,
    ):
        super().__init__(
            message,
            code="DASHBOARD_CACHE_ERROR",
            details={"cache_key": cache_key, "operation": operation},
        )


class DashboardDatabaseError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì˜¤ë¥˜"""

    def __init__(
        self, message: str, operation: Optional[str] = None, table: Optional[str] = None
    ):
        super().__init__(
            message,
            code="DASHBOARD_DATABASE_ERROR",
            details={"operation": operation, "table": table},
        )


class DashboardConfigurationError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ì„¤ì • ê´€ë ¨ ì˜¤ë¥˜"""

    def __init__(
        self,
        message: str,
        setting_key: Optional[str] = None,
        setting_value: Optional[Any] = None,
    ):
        super().__init__(
            message,
            code="DASHBOARD_CONFIGURATION_ERROR",
            details={
                "setting_key": setting_key,
                "setting_value": str(setting_value)
                if setting_value is not None
                else None,
            },
        )


class DashboardTimeoutError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ ì‘ì—… ì‹œê°„ ì´ˆê³¼"""

    def __init__(
        self,
        message: str,
        timeout_seconds: Optional[int] = None,
        operation: Optional[str] = None,
    ):
        super().__init__(
            message,
            code="DASHBOARD_TIMEOUT_ERROR",
            details={"timeout_seconds": timeout_seconds, "operation": operation},
        )


class DashboardQuotaExceededError(DashboardServiceError):
    """ëŒ€ì‹œë³´ë“œ í• ë‹¹ëŸ‰ ì´ˆê³¼"""

    def __init__(
        self,
        message: str,
        quota_type: Optional[str] = None,
        current_value: Optional[int] = None,
        limit: Optional[int] = None,
    ):
        super().__init__(
            message,
            code="DASHBOARD_QUOTA_EXCEEDED",
            details={
                "quota_type": quota_type,
                "current_value": current_value,
                "limit": limit,
            },
        )


# ============================================================================
# ëŒ€ì‹œë³´ë“œ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
# ============================================================================


class DashboardService:
    """ëŒ€ì‹œë³´ë“œ ë¶„ì„ ë° ìš”ì•½ ë°ì´í„°ë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤"""

    def __init__(self, db: AsyncSession):
        self.db = db

    async def _get_user_project_ids(self, user_id: UUID) -> List[UUID]:
        """
        ì‚¬ìš©ìê°€ ë©¤ë²„ë¡œ í¬í•¨ëœ í”„ë¡œì íŠ¸ ID ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        try:
            print(f"ğŸ” [DEBUG] _get_user_project_ids ì‹œì‘ - user_id: {user_id}")

            # ë°©ë²• 1: ì†Œìœ í•œ í”„ë¡œì íŠ¸ ì¡°íšŒ
            owned_projects_query = select(Project.id).where(Project.owner_id == user_id)
            owned_result = await self.db.execute(owned_projects_query)
            owned_project_ids = [row[0] for row in owned_result.fetchall()]

            print(f"âœ… [DEBUG] ì†Œìœ í•œ í”„ë¡œì íŠ¸ ìˆ˜: {len(owned_project_ids)}")

            # ë°©ë²• 2: ProjectMember í…Œì´ë¸”ì„ í†µí•œ ë©¤ë²„ í”„ë¡œì íŠ¸ ì¡°íšŒ
            # (ProjectMember í…Œì´ë¸”ì´ ìˆë‹¤ê³  ê°€ì •)
            try:
                member_projects_query = select(ProjectMember.project_id).where(
                    ProjectMember.user_id == user_id
                )
                member_result = await self.db.execute(member_projects_query)
                member_project_ids = [row[0] for row in member_result.fetchall()]

                print(
                    f"âœ… [DEBUG] ë©¤ë²„ë¡œ ì°¸ì—¬í•œ í”„ë¡œì íŠ¸ ìˆ˜: {len(member_project_ids)}"
                )
            except Exception as member_error:
                print(
                    f"âš ï¸ [DEBUG] ProjectMember í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨ (í…Œì´ë¸”ì´ ì—†ì„ ìˆ˜ ìˆìŒ): {member_error}"
                )
                member_project_ids = []

            # ì¤‘ë³µ ì œê±°í•˜ì—¬ í•©ì¹˜ê¸°
            all_project_ids = list(set(owned_project_ids + member_project_ids))

            print(f"âœ… [DEBUG] ì „ì²´ ì ‘ê·¼ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ ìˆ˜: {len(all_project_ids)}")

            return all_project_ids

        except Exception as e:
            print(f"âŒ [DEBUG] _get_user_project_ids ì˜¤ë¥˜: {e}")
            logger.error("í”„ë¡œì íŠ¸ ID ì¡°íšŒ ì‹¤íŒ¨: %s", str(e))
            return []

    def _extract_uuid(self, obj: Any) -> Optional[UUID]:
        """SQLAlchemy ê°ì²´ì—ì„œ UUID ê°’ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
        if obj is None:
            return None

        if isinstance(obj, UUID):
            return obj

        try:
            return UUID(str(obj))
        except (ValueError, TypeError):
            return None

    # ============================================================================
    # API í˜¸í™˜ì„±ì„ ìœ„í•œ ì¶”ê°€ ë©”ì„œë“œë“¤
    # ============================================================================

    async def get_project_status_stats(self, user_id: UUID) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ìƒíƒœë³„ í†µê³„"""
        try:
            project_stats = await self.get_project_stats(user_id)
            return {
                "total_projects": project_stats.get("total_projects", 0),
                "by_status": project_stats.get("by_status", {}),
                "by_priority": project_stats.get("by_priority", {}),
                "completion_rates": {},
                "overdue_count": 0,
            }
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(
                f"í”„ë¡œì íŠ¸ ìƒíƒœë³„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
            ) from e

    async def get_task_status_stats(self, user_id: UUID) -> Dict[str, Any]:
        """ì‘ì—… ìƒíƒœë³„ í†µê³„"""
        try:
            task_stats = await self.get_task_stats(user_id)
            return {
                "total_tasks": task_stats.get("total_tasks", 0),
                "by_status": task_stats.get("by_status", {}),
                "by_priority": task_stats.get("by_priority", {}),
                "by_assignee": task_stats.get("by_assignee", {}),
                "overdue_count": task_stats.get("overdue_tasks", 0),
                "completion_trend": [],
            }
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì‘ì—… ìƒíƒœë³„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_user_workload_stats(self, user_id: UUID) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì›Œí¬ë¡œë“œ í†µê³„"""
        try:
            task_stats = await self.get_task_stats(user_id)
            current_workload = task_stats.get("assigned_to_me", 0)

            return {
                "current_workload": current_workload,
                "capacity_utilization": min(100.0, (current_workload / 10) * 100),
                "workload_distribution": {},
                "overdue_workload": task_stats.get("overdue_tasks", 0),
                "estimated_completion": None,
                "burnout_risk": "low",
            }
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(
                f"ì‚¬ìš©ì ì›Œí¬ë¡œë“œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
            ) from e

    async def get_dashboard_overview(
        self,
        user_id: UUID,
        period: str = "7d",
        include_charts: bool = True,
    ) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ê°œìš” ì¡°íšŒ"""
        try:
            stats = await self.get_user_summary(user_id, period)

            overview = {
                "stats": stats,
                "key_metrics": {
                    "completion_rate": stats.get("completion_rate", 0.0),
                    "productivity_score": stats.get("productivity_score", 0.0),
                    "overdue_tasks": stats.get("overdue_tasks", 0),
                },
                "widgets": [
                    {"type": "stats", "data": stats},
                    {
                        "type": "recent_activity",
                        "data": stats.get("recent_activity", []),
                    },
                    {
                        "type": "upcoming_events",
                        "data": stats.get("upcoming_events", []),
                    },
                ],
            }

            if include_charts:
                overview["charts"] = {
                    "task_status": stats.get("tasks", {}).get("by_status", {}),
                    "project_status": stats.get("projects", {}).get("by_status", {}),
                }

            return overview
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ëŒ€ì‹œë³´ë“œ ê°œìš” ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def log_user_activity(
        self, user_id: UUID, activity_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì í™œë™ ë¡œê·¸ ê¸°ë¡"""
        try:
            await self._verify_user_access(user_id)

            activity_log = UserActivityLog(
                user_id=user_id,
                action=activity_data.get("action", "unknown"),
                description=activity_data.get("description", ""),
                resource_type=activity_data.get("resource_type"),
                resource_id=activity_data.get("resource_id"),
                ip_address=activity_data.get("ip_address"),
                user_agent=activity_data.get("user_agent"),
            )

            self.db.add(activity_log)
            await self.db.commit()
            await self.db.refresh(activity_log)

            return {
                "id": str(activity_log.id),
                "status": "logged",
                "created_at": activity_log.created_at,
            }

        except SQLAlchemyError as e:
            await self.db.rollback()
            logger.error("ì‚¬ìš©ì í™œë™ ë¡œê·¸ ê¸°ë¡ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: %s", str(e))
            raise DashboardDatabaseError(
                "ì‚¬ìš©ì í™œë™ ë¡œê·¸ë¥¼ ê¸°ë¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                operation="log_user_activity",
                table="user_activity_logs",
            ) from e
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì‚¬ìš©ì í™œë™ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {str(e)}") from e

    async def _calculate_productivity_score(self, user_id: UUID) -> float:
        """ìƒì‚°ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            task_stats = await self.get_task_stats(user_id)

            total_tasks = task_stats.get("assigned_to_me", 0)
            completed_tasks = task_stats.get("by_status", {}).get("completed", 0)
            overdue_tasks = task_stats.get("overdue_tasks", 0)

            if total_tasks == 0:
                return 0.0

            completion_score = (completed_tasks / total_tasks) * 100
            overdue_penalty = min(overdue_tasks * 10, 50)

            productivity_score = max(0, completion_score - overdue_penalty)
            return round(productivity_score, 2)

        except Exception as e:
            logger.error("ìƒì‚°ì„± ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: %s", str(e))
            return 0.0

    # ============================================================================
    # ìˆ˜ì •ëœ _parse_period ë©”ì„œë“œ (f-string ì‚¬ìš©)
    # ============================================================================

    def _parse_period(self, period: str) -> timedelta:
        """ê¸°ê°„ ë¬¸ìì—´ì„ timedeltaë¡œ ë³€í™˜"""
        period_map = {
            "1d": timedelta(days=1),
            "7d": timedelta(days=7),
            "30d": timedelta(days=30),
            "90d": timedelta(days=90),
        }
        if period not in period_map:
            raise DashboardValidationError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ê°„ í˜•ì‹ì…ë‹ˆë‹¤: {period}",
                field="period",
                value=period,
            )
        return period_map[period]

    # ============================================================================
    # ìˆ˜ì •ëœ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ë©”ì„œë“œë“¤ (f-string ì‚¬ìš©)
    # ============================================================================

    async def export_dashboard_data_sync(
        self,
        user_id: UUID,
        export_format: str,
    ) -> tuple:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë‚´ë³´ë‚´ê¸° (ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ, sync ë©”ì„œë“œë¡œ ì´ë¦„ ë³€ê²½)"""
        try:
            await self._verify_user_access(user_id)

            # ë°ì´í„° ìˆ˜ì§‘
            stats = await self.get_user_summary(user_id)

            if export_format == "json":
                content = StringIO(json.dumps(stats, default=str, indent=2))
                filename = (
                    f"dashboard_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                )
                media_type = "application/json"
            elif export_format == "csv":
                content = StringIO()
                writer = csv.writer(content)
                writer.writerow(["Metric", "Value"])
                for key, value in stats.items():
                    writer.writerow([key, str(value)])
                content.seek(0)
                filename = (
                    f"dashboard_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                )
                media_type = "text/csv"
            else:
                raise DashboardValidationError(
                    f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ë³´ë‚´ê¸° í˜•ì‹: {export_format}",
                    field="format",
                    value=export_format,
                )

            return content, filename, media_type

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardExportError(
                f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}",
                export_format=export_format,
            ) from e

    async def get_export_status_sync(
        self, user_id: UUID, export_id: str
    ) -> Dict[str, Any]:
        """ë‚´ë³´ë‚´ê¸° ìƒíƒœ í™•ì¸ (ë™ê¸°ì‹/ì„ì‹œ ë©”ì„œë“œ)"""
        try:
            await self._verify_user_access(user_id)

            return {
                "status": "completed",
                "progress": 100.0,
                "download_url": f"/api/dashboard/export/{export_id}/download",
                "expires_at": datetime.now(timezone.utc) + timedelta(hours=24),
                "error_message": None,
                "created_at": datetime.now(timezone.utc),
            }

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardExportError(
                f"ë‚´ë³´ë‚´ê¸° ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}",
                export_id=export_id,
            ) from e

    async def download_export_sync(self, user_id: UUID, export_id: str) -> tuple:
        """ë‚´ë³´ë‚¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ë™ê¸°ì‹/ì„ì‹œ ë©”ì„œë“œ)"""
        try:
            await self._verify_user_access(user_id)

            # ì„ì‹œë¡œ JSON ë°ì´í„° ë°˜í™˜
            stats = await self.get_user_summary(user_id)

            content = StringIO(json.dumps(stats, default=str, indent=2))
            filename = f"export_{export_id}.json"
            media_type = "application/json"

            return content, filename, media_type

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardExportError(
                f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}",
                export_id=export_id,
            ) from e

    async def cancel_export(self, user_id: UUID, export_id: str) -> Dict[str, Any]:
        """ë‚´ë³´ë‚´ê¸° ì‘ì—… ì·¨ì†Œ"""
        try:
            await self._verify_user_access(user_id)

            # export_id ìœ íš¨ì„± ê²€ì¦
            try:
                UUID(export_id)
            except ValueError as e:
                raise DashboardValidationError(
                    f"ìœ íš¨í•˜ì§€ ì•Šì€ ë‚´ë³´ë‚´ê¸° IDì…ë‹ˆë‹¤: {str(e)}",
                    field="export_id",
                    value=export_id,
                ) from e

            logger.info(
                "ë‚´ë³´ë‚´ê¸° ì‘ì—… ì·¨ì†Œ: user_id=%s, export_id=%s", user_id, export_id
            )

            # ì‹¤ì œ êµ¬í˜„ ì‹œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì·¨ì†Œ ë¡œì§ í•„ìš”
            # ì˜ˆ: ì§„í–‰ ì¤‘ì¸ ì‘ì—… ì¤‘ë‹¨, ì„ì‹œ íŒŒì¼ ì •ë¦¬ ë“±

            return {
                "status": "cancelled",
                "export_id": export_id,
                "cancelled_at": datetime.now(timezone.utc),
                "message": "ë‚´ë³´ë‚´ê¸° ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤",
            }

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except Exception as e:
            logger.error("ë‚´ë³´ë‚´ê¸° ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜: %s", str(e))
            raise DashboardExportError(
                f"ë‚´ë³´ë‚´ê¸° ì·¨ì†Œ ì‹¤íŒ¨: {str(e)}",
                export_id=export_id,
            ) from e

    # ============================================================================
    # ìˆ˜ì •ëœ ì˜ˆì™¸ ì²˜ë¦¬ ë©”ì„œë“œë“¤ (f-string ì‚¬ìš©)
    # ============================================================================

    async def _verify_user_access(self, user_id: UUID) -> None:
        """ì‚¬ìš©ì ì ‘ê·¼ ê¶Œí•œ í™•ì¸"""
        try:
            user_query = select(User).where(User.id == user_id)
            result = await self.db.execute(user_query)
            user = result.scalar_one_or_none()

            if not user:
                raise DashboardDataNotFoundError(
                    "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    resource_type="user",
                    resource_id=str(user_id),
                )

            if not getattr(user, "is_active", True):
                raise DashboardPermissionError(
                    "ë¹„í™œì„±í™”ëœ ì‚¬ìš©ìì…ë‹ˆë‹¤",
                    required_permission="active_user",
                    user_id=str(user_id),
                )
        except SQLAlchemyError as e:
            logger.error("ì‚¬ìš©ì ì ‘ê·¼ ê¶Œí•œ í™•ì¸ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: %s", e)
            raise DashboardDatabaseError(
                "ì‚¬ìš©ì ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                operation="verify_user_access",
                table="users",
            ) from e

    async def get_user_summary(
        self,
        user_id: UUID,
        period: str = "7d",
        search: Optional[str] = None,
    ) -> Dict[str, Any]:
        """í˜„ì¬ ì‚¬ìš©ìì˜ ì¢…í•© ëŒ€ì‹œë³´ë“œ ìš”ì•½ ì¡°íšŒ"""
        try:
            logger.info("ì‚¬ìš©ì ìš”ì•½ ì¡°íšŒ ì‹œì‘: user_id=%s, period=%s", user_id, period)

            await self._verify_user_access(user_id)
            self._parse_period(period)  # ìœ íš¨ì„± ê²€ì¦

            project_stats = await self.get_project_stats(user_id)
            task_stats = await self.get_task_stats(user_id)
            recent_activity = await self.get_recent_activity(user_id, search=search)
            upcoming_events = await self.get_upcoming_events(user_id, search=search)

            print(
                f"ğŸ” [DEBUG] recent_activity íƒ€ì…: {type(recent_activity)}, ê¸¸ì´: {len(recent_activity) if isinstance(recent_activity, list) else 'N/A'}"
            )
            print(
                f"ğŸ” [DEBUG] upcoming_events íƒ€ì…: {type(upcoming_events)}, ê¸¸ì´: {len(upcoming_events) if isinstance(upcoming_events, list) else 'N/A'}"
            )

            # DashboardStatsResponse í˜•ì‹ì— ë§ì¶° ì‘ë‹µ êµ¬ì„±
            summary = {
                # í”„ë¡œì íŠ¸ í†µê³„
                "total_projects": project_stats.get("total_projects", 0),
                "active_projects": project_stats.get("by_status", {}).get("active", 0),
                "completed_projects": project_stats.get("by_status", {}).get(
                    "completed", 0
                ),
                # ì‘ì—… í†µê³„
                "total_tasks": task_stats.get("total_tasks", 0),
                "pending_tasks": task_stats.get("by_status", {}).get("todo", 0),
                "in_progress_tasks": task_stats.get("by_status", {}).get(
                    "in_progress", 0
                ),
                "completed_tasks": task_stats.get("by_status", {}).get("completed", 0),
                "overdue_tasks": task_stats.get("overdue_tasks", 0),
                # ì‹œê°„ ê´€ë ¨ í†µê³„
                "total_time_spent": 0.0,
                "avg_completion_time": 0.0,
                # ì„±ê³¼ ì§€í‘œ
                "completion_rate": task_stats.get("completion_rate", 0.0),
                "productivity_score": await self._calculate_productivity_score(user_id),
                # ê¸°ê°„ ë° ë©”íƒ€ë°ì´í„°
                "period": period,
                "last_updated": datetime.now(timezone.utc),
                # ì´ë²¤íŠ¸ ë° ì•Œë¦¼ ê°œìˆ˜ (ì •ìˆ˜ë¡œ ë°˜í™˜)
                "upcoming_events": len(upcoming_events)
                if isinstance(upcoming_events, list)
                else 0,
                "total_events": len(upcoming_events)
                if isinstance(upcoming_events, list)
                else 0,
                "notifications_count": 0,
                "unread_notifications": 0,
                # í”„ë¡œì íŠ¸ì™€ ì‘ì—… ìƒì„¸ ì •ë³´
                "projects": {
                    "total_projects": project_stats.get("total_projects", 0),
                    "by_status": project_stats.get("by_status", {}),
                    "by_priority": project_stats.get("by_priority", {}),
                },
                "tasks": {
                    "total_tasks": task_stats.get("total_tasks", 0),
                    "by_status": task_stats.get("by_status", {}),
                    "by_priority": task_stats.get("by_priority", {}),
                    "assigned_to_user": task_stats.get("assigned_to_me", 0),
                    "overdue_tasks": task_stats.get("overdue_tasks", 0),
                },
                # ìµœê·¼ í™œë™ ëª©ë¡ (ë°°ì—´ë¡œ ë°˜í™˜)
                "recent_activity": recent_activity[:10]
                if isinstance(recent_activity, list)
                else [],
            }

            print(
                f"âœ… [DEBUG] summary ìƒì„± ì™„ë£Œ - total_events: {summary['total_events']}"
            )
            return summary

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ - ì‚¬ìš©ì ìš”ì•½ ì¡°íšŒ: %s", str(e))
            raise DashboardDatabaseError(
                f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‚¬ìš©ì ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                operation="get_user_summary",
            ) from e
        except Exception as e:
            logger.error("ì‚¬ìš©ì ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: user_id=%s, error=%s", user_id, str(e))
            raise DashboardServiceError(f"ì‚¬ìš©ì ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_comprehensive_stats(
        self,
        user_id: UUID,
        period: str = "7d",
        search: Optional[str] = None,
    ) -> Dict[str, Any]:
        """í¬ê´„ì ì¸ í†µê³„ ë°ì´í„° ì¡°íšŒ (API í˜¸í™˜ì„±)"""
        try:
            return await self.get_user_summary(user_id, period, search)
        except Exception as e:
            logger.error("í¬ê´„ì  í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: %s", str(e))
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"í¬ê´„ì  í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_project_stats(self, user_id: UUID) -> Dict[str, Any]:
        """í˜„ì¬ ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ í†µê³„ ì¡°íšŒ"""
        try:
            logger.info("í”„ë¡œì íŠ¸ í†µê³„ ì¡°íšŒ ì‹œì‘: user_id=%s", user_id)

            await self._verify_user_access(user_id)

            # ì‚¬ìš©ìê°€ ë©¤ë²„ì¸ í”„ë¡œì íŠ¸ ì¡°íšŒ
            project_ids = await self._get_user_project_ids(user_id)

            if not project_ids:
                return {
                    "total_projects": 0,
                    "by_status": {},
                    "by_priority": {},
                    "owned_projects": 0,
                    "completion_rate": 0.0,
                }

            # ì „ì²´ í”„ë¡œì íŠ¸ ìˆ˜
            total_query = select(count(Project.id)).where(Project.id.in_(project_ids))
            total_result = await self.db.execute(total_query)
            total_projects = total_result.scalar() or 0

            # ìƒíƒœë³„ í”„ë¡œì íŠ¸ ìˆ˜
            status_query = (
                select(Project.status, count(Project.id))
                .where(Project.id.in_(project_ids))
                .group_by(Project.status)
            )
            status_result = await self.db.execute(status_query)
            by_status = {str(row[0]): row[1] for row in status_result.fetchall()}

            # ìš°ì„ ìˆœìœ„ë³„ í”„ë¡œì íŠ¸ ìˆ˜
            priority_query = (
                select(Project.priority, count(Project.id))
                .where(Project.id.in_(project_ids))
                .group_by(Project.priority)
            )
            priority_result = await self.db.execute(priority_query)
            by_priority = {str(row[0]): row[1] for row in priority_result.fetchall()}

            # ì†Œìœ í•œ í”„ë¡œì íŠ¸ ìˆ˜
            owned_query = select(count(Project.id)).where(
                and_(Project.owner_id == user_id, Project.id.in_(project_ids))
            )
            owned_result = await self.db.execute(owned_query)
            owned_projects = owned_result.scalar() or 0

            # ì™„ë£Œìœ¨ ê³„ì‚°
            completed_count = by_status.get("completed", 0)
            completion_rate = (
                (completed_count / total_projects * 100) if total_projects > 0 else 0.0
            )

            return {
                "total_projects": total_projects,
                "by_status": by_status,
                "by_priority": by_priority,
                "owned_projects": owned_projects,
                "completion_rate": round(completion_rate, 2),
            }

        except (DashboardDataNotFoundError, DashboardPermissionError):
            raise
        except SQLAlchemyError as e:
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ - í”„ë¡œì íŠ¸ í†µê³„ ì¡°íšŒ: %s", str(e))
            raise DashboardDatabaseError(
                f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ë¡œ ì¸í•œ í”„ë¡œì íŠ¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                operation="get_project_stats",
                table="projects",
            ) from e
        except Exception as e:
            logger.error(
                "í”„ë¡œì íŠ¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: user_id=%s, error=%s", user_id, str(e)
            )
            raise DashboardServiceError(f"í”„ë¡œì íŠ¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_task_stats(self, user_id: UUID) -> Dict[str, Any]:
        """í˜„ì¬ ì‚¬ìš©ìì˜ ì‘ì—… í†µê³„ ì¡°íšŒ"""
        try:
            logger.info("ì‘ì—… í†µê³„ ì¡°íšŒ ì‹œì‘: user_id=%s", user_id)

            await self._verify_user_access(user_id)

            # ì‚¬ìš©ìê°€ ì ‘ê·¼ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ ì¡°íšŒ
            project_ids = await self._get_user_project_ids(user_id)

            if not project_ids:
                return {
                    "total_tasks": 0,
                    "assigned_to_me": 0,
                    "assigned_to_user": 0,
                    "created_by_me": 0,
                    "by_status": {},
                    "by_priority": {},
                    "by_assignee": {},
                    "overdue_tasks": 0,
                    "completion_rate": 0.0,
                }

            # ì ‘ê·¼ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ì˜ ì „ì²´ ì‘ì—… ìˆ˜
            total_query = select(count(Task.id)).where(Task.project_id.in_(project_ids))
            total_result = await self.db.execute(total_query)
            total_tasks = total_result.scalar() or 0

            # ì‚¬ìš©ìì—ê²Œ í• ë‹¹ëœ ì‘ì—… ìˆ˜
            assigned_subquery = select(TaskAssignment.task_id).where(
                and_(
                    TaskAssignment.user_id == user_id,
                    TaskAssignment.is_active.is_(True),
                )
            )
            assigned_query = select(count(Task.id)).where(
                and_(
                    Task.project_id.in_(project_ids),
                    Task.id.in_(assigned_subquery),
                )
            )
            assigned_result = await self.db.execute(assigned_query)
            assigned_to_me = assigned_result.scalar() or 0

            # ì‚¬ìš©ìê°€ ìƒì„±í•œ ì‘ì—… ìˆ˜
            created_query = select(count(Task.id)).where(
                and_(
                    Task.project_id.in_(project_ids),
                    or_(
                        Task.owner_id == user_id,
                        Task.created_by == user_id,
                    ),
                )
            )
            created_result = await self.db.execute(created_query)
            created_by_me = created_result.scalar() or 0

            # í• ë‹¹ëœ ì‘ì—…ì˜ ìƒíƒœë³„ ë¶„í¬
            status_query = text("""
                SELECT t.status, COUNT(t.id)
                FROM tasks t
                JOIN task_assignments ta ON t.id = ta.task_id
                WHERE t.project_id = ANY(:project_ids)
                  AND ta.user_id = :user_id
                  AND ta.is_active = true
                GROUP BY t.status
            """)
            status_result = await self.db.execute(
                status_query, {"project_ids": project_ids, "user_id": user_id}
            )
            by_status = {str(row[0]): row[1] for row in status_result.fetchall()}

            # í• ë‹¹ëœ ì‘ì—…ì˜ ìš°ì„ ìˆœìœ„ë³„ ë¶„í¬
            priority_query = (
                select(Task.priority, count(Task.id))
                .where(
                    and_(
                        Task.project_id.in_(project_ids),
                        Task.id.in_(assigned_subquery),
                    )
                )
                .group_by(Task.priority)
            )
            priority_result = await self.db.execute(priority_query)
            by_priority = {str(row[0]): row[1] for row in priority_result.fetchall()}

            # ë‹´ë‹¹ìë³„ ì‘ì—… ë¶„í¬
            assignee_query = (
                select(TaskAssignment.user_id, count(TaskAssignment.task_id))
                .select_from(TaskAssignment)
                .join(Task, Task.id == TaskAssignment.task_id)
                .where(
                    and_(
                        Task.project_id.in_(project_ids),
                        TaskAssignment.is_active.is_(True),
                    )
                )
                .group_by(TaskAssignment.user_id)
            )
            assignee_result = await self.db.execute(assignee_query)
            by_assignee = {str(row[0]): row[1] for row in assignee_result.fetchall()}

            # ì§€ì—°ëœ ì‘ì—… ìˆ˜
            overdue_query = select(count(Task.id)).where(
                and_(
                    Task.project_id.in_(project_ids),
                    Task.id.in_(assigned_subquery),
                    Task.due_date.isnot(None),
                    Task.due_date < datetime.now(timezone.utc),
                    Task.status.in_(["todo", "in_progress", "in_review", "testing"]),
                )
            )
            overdue_result = await self.db.execute(overdue_query)
            overdue_tasks = overdue_result.scalar() or 0

            # ì™„ë£Œìœ¨ ê³„ì‚°
            completed_count = by_status.get("completed", 0)
            completion_rate = (
                (completed_count / assigned_to_me * 100) if assigned_to_me > 0 else 0.0
            )

            return {
                "total_tasks": total_tasks,
                "assigned_to_me": assigned_to_me,
                "assigned_to_user": assigned_to_me,
                "created_by_me": created_by_me,
                "by_status": by_status,
                "by_priority": by_priority,
                "by_assignee": by_assignee,
                "overdue_tasks": overdue_tasks,
                "completion_rate": round(completion_rate, 2),
            }

        except (DashboardDataNotFoundError, DashboardPermissionError):
            raise
        except SQLAlchemyError as e:
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ - ì‘ì—… í†µê³„ ì¡°íšŒ: %s", str(e))
            raise DashboardDatabaseError(
                f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‘ì—… í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                operation="get_task_stats",
                table="tasks",
            ) from e
        except Exception as e:
            logger.error("ì‘ì—… í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: user_id=%s, error=%s", user_id, str(e))
            raise DashboardServiceError(f"ì‘ì—… í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_recent_activity(
        self,
        user_id: UUID,
        page_size: int = 10,
        page_no: int = 0,
        search: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """í˜„ì¬ ì‚¬ìš©ìì˜ ìµœê·¼ í™œë™ ì¡°íšŒ"""
        try:
            logger.info("ìµœê·¼ í™œë™ ì¡°íšŒ ì‹œì‘: user_id=%s, limit=%s", user_id, page_size)

            await self._verify_user_access(user_id)

            if page_size <= 0 or page_size > 100:
                raise DashboardValidationError(
                    "page_size 1-100 ì‚¬ì´ì˜ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤",
                    field="page_size",
                    value=page_size,
                )

            if page_no < 0:
                raise DashboardValidationError(
                    "page_noì€ 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤", field="page_no", value=page_no
                )

            query = select(UserActivityLog).where(UserActivityLog.user_id == user_id)

            # ê²€ìƒ‰ì–´ê°€ ìˆëŠ” ê²½ìš° í•„í„° ì¶”ê°€
            if search:
                search_pattern = "%" + search + "%"
                query = query.where(
                    or_(
                        UserActivityLog.action.ilike(search_pattern),
                        UserActivityLog.description.ilike(search_pattern),
                        UserActivityLog.resource_type.ilike(search_pattern),
                    )
                )

            query = (
                query.order_by(UserActivityLog.created_at.desc())
                .offset(page_no)
                .limit(page_size)
            )

            result = await self.db.execute(query)
            activities = result.scalars().all()

            return [
                {
                    "id": str(activity.id),
                    "type": "user_action",
                    "action": activity.action or "Unknown Action",
                    "description": activity.description or "",
                    "user_name": "User",
                    "user_avatar": None,
                    "resource_type": activity.resource_type,
                    "resource_id": activity.resource_id,
                    "resource_name": None,
                    "timestamp": activity.created_at,
                    "created_at": activity.created_at,
                    "metadata": {
                        "ip_address": getattr(activity, "ip_address", None),
                        "user_agent": getattr(activity, "user_agent", None),
                    },
                }
                for activity in activities
            ]

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ - ìµœê·¼ í™œë™ ì¡°íšŒ: %s", str(e))
            raise DashboardDatabaseError(
                f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ë¡œ ì¸í•œ ìµœê·¼ í™œë™ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                operation="get_recent_activity",
                table="user_activity_logs",
            ) from e
        except Exception as e:
            logger.error("ìµœê·¼ í™œë™ ì¡°íšŒ ì‹¤íŒ¨: user_id=%s, error=%s", user_id, str(e))
            raise DashboardServiceError(f"ìµœê·¼ í™œë™ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_upcoming_events(
        self, user_id: UUID, limit: int = 5, days: int = 7, search: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """í˜„ì¬ ì‚¬ìš©ìì˜ ë‹¤ê°€ì˜¤ëŠ” ì¼ì • ì¡°íšŒ"""
        try:
            print(
                f"ğŸ” [DEBUG] get_upcoming_events ì‹œì‘ - user_id: {user_id}, limit: {limit}, days: {days}"
            )

            logger.info("ë‹¤ê°€ì˜¤ëŠ” ì¼ì • ì¡°íšŒ ì‹œì‘: user_id=%s, days=%s", user_id, days)

            await self._verify_user_access(user_id)

            if limit <= 0 or limit > 50:
                raise DashboardValidationError(
                    "limitì€ 1-50 ì‚¬ì´ì˜ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤", field="limit", value=limit
                )

            if days <= 0 or days > 365:
                raise DashboardValidationError(
                    "daysëŠ” 1-365 ì‚¬ì´ì˜ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤", field="days", value=days
                )

            end_date = datetime.now(timezone.utc) + timedelta(days=days)

            try:
                query = (
                    select(Event)
                    .join(Calendar)
                    .where(
                        and_(
                            Calendar.owner_id == user_id,
                            Event.start_time >= datetime.now(timezone.utc),
                            Event.start_time <= end_date,
                        )
                    )
                )

                # ê²€ìƒ‰ì–´ê°€ ìˆëŠ” ê²½ìš° í•„í„° ì¶”ê°€
                if search:
                    search_pattern = "%" + search + "%"
                    query = query.where(
                        or_(
                            Event.title.ilike(search_pattern),
                            Event.description.ilike(search_pattern),
                        )
                    )

                query = query.order_by(Event.start_time).limit(limit)

                result = await self.db.execute(query)
                events = result.scalars().all()

                print(f"âœ… [DEBUG] ì´ë²¤íŠ¸ ì¡°íšŒ ì™„ë£Œ - ì´ë²¤íŠ¸ ìˆ˜: {len(events)}")

                event_list = [
                    {
                        "id": str(event.id),
                        "title": event.title,
                        "description": getattr(event, "description", ""),
                        "type": "meeting",
                        "priority": "medium",
                        "start_time": event.start_time,
                        "end_time": getattr(
                            event, "end_time", event.start_time + timedelta(hours=1)
                        ),
                        "duration": 60,  # ê¸°ë³¸ 60ë¶„
                        "location": getattr(event, "location", ""),
                        "attendees": [],
                        "attendee_count": 0,
                        "project_id": None,
                        "project_name": None,
                        "is_recurring": False,
                        "reminder_set": False,
                        "calendar_name": "ê¸°ë³¸ ìº˜ë¦°ë”",
                        "status": "confirmed",
                    }
                    for event in events
                ]

                print(
                    f"âœ… [DEBUG] get_upcoming_events ì™„ë£Œ - ë°˜í™˜í•  ì´ë²¤íŠ¸ ìˆ˜: {len(event_list)}"
                )
                return event_list

            except Exception as query_error:
                print(f"âš ï¸ [DEBUG] ì´ë²¤íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜): {query_error}")
                # ì´ë²¤íŠ¸ í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
                return []

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ - ë‹¤ê°€ì˜¤ëŠ” ì¼ì • ì¡°íšŒ: %s", str(e))
            print(f"âŒ [DEBUG] SQLAlchemy ì˜¤ë¥˜ - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜: {e}")
            return []  # ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        except Exception as e:
            logger.error(
                "ë‹¤ê°€ì˜¤ëŠ” ì¼ì • ì¡°íšŒ ì‹¤íŒ¨: user_id=%s, error=%s", user_id, str(e)
            )
            print(f"âŒ [DEBUG] ì¼ë°˜ ì˜¤ë¥˜ - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜: {e}")
            return []  # ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    # ============================================================================
    # í™œë™ ìƒì„¸ ì¡°íšŒ ë©”ì„œë“œë“¤
    # ============================================================================

    async def get_activity_detail(
        self, user_id: UUID, activity_id: str
    ) -> Dict[str, Any]:
        """í™œë™ ìƒì„¸ ì¡°íšŒ"""
        try:
            await self._verify_user_access(user_id)

            activity_uuid = self._extract_uuid(activity_id)
            if not activity_uuid:
                raise DashboardValidationError(
                    "ìœ íš¨í•˜ì§€ ì•Šì€ í™œë™ IDì…ë‹ˆë‹¤",
                    field="activity_id",
                    value=activity_id,
                )

            query = select(UserActivityLog).where(
                and_(
                    UserActivityLog.id == activity_uuid,
                    UserActivityLog.user_id == user_id,
                )
            )
            result = await self.db.execute(query)
            activity = result.scalar_one_or_none()

            if not activity:
                raise DashboardDataNotFoundError(
                    "í™œë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    resource_type="activity",
                    resource_id=activity_id,
                )

            return {
                "id": str(activity.id),
                "type": "user_action",
                "action": activity.action,
                "description": activity.description or "",
                "resource_type": activity.resource_type,
                "resource_id": activity.resource_id,
                "resource_name": None,
                "user_id": str(user_id),
                "user_name": "User",
                "timestamp": activity.created_at,
                "metadata": {
                    "ip_address": getattr(activity, "ip_address", None),
                    "user_agent": getattr(activity, "user_agent", None),
                },
            }

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("í™œë™ ìƒì„¸ ì¡°íšŒ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: %s", str(e))
            raise DashboardDatabaseError(
                "í™œë™ ìƒì„¸ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                operation="get_activity_detail",
                table="user_activity_logs",
            ) from e
        except Exception as e:
            logger.error("í™œë™ ìƒì„¸ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", str(e))
            raise DashboardServiceError(f"í™œë™ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_user_activities(
        self,
        current_user_id: UUID,
        target_user_id: str,
        page_size: int = 20,
        page_no: int = 1,
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ìë³„ í™œë™ ë‚´ì—­ ì¡°íšŒ"""
        try:
            await self._verify_user_access(current_user_id)

            target_uuid = self._extract_uuid(target_user_id)
            if not target_uuid:
                raise DashboardValidationError(
                    "ìœ íš¨í•˜ì§€ ì•Šì€ ì‚¬ìš©ì IDì…ë‹ˆë‹¤",
                    field="target_user_id",
                    value=target_user_id,
                )

            # ê¶Œí•œ í™•ì¸ - ë³¸ì¸ì´ê±°ë‚˜ ê´€ë¦¬ìì¸ ê²½ìš°ë§Œ í—ˆìš©
            if current_user_id != target_uuid:
                raise DashboardPermissionError(
                    "ë‹¤ë¥¸ ì‚¬ìš©ìì˜ í™œë™ì„ ì¡°íšŒí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤",
                    required_permission="view_other_user_activities",
                    user_id=str(current_user_id),
                )

            if page_size <= 0 or page_size > 100:
                raise DashboardValidationError(
                    "page_sizeëŠ” 1-100 ì‚¬ì´ì˜ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤",
                    field="page_size",
                    value=page_size,
                )

            if page_no <= 0:
                raise DashboardValidationError(
                    "page_noëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤", field="page_no", value=page_no
                )

            page_no = (page_no - 1) * page_size

            activities = await self.get_recent_activity(
                user_id=target_uuid, page_size=page_size, page_no=page_no
            )

            total = len(activities)  # ì‹¤ì œë¡œëŠ” ë³„ë„ ì¿¼ë¦¬ë¡œ ì „ì²´ ê°œìˆ˜ ì¡°íšŒ í•„ìš”
            total_pages = (total + page_size - 1) // page_size

            return {
                "activities": activities,
                "page_no": page_no,
                "page_size": page_size,
                "total_pages": total_pages,
                "total_items": total,
            }

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ì‚¬ìš©ì í™œë™ ë‚´ì—­ ì¡°íšŒ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: %s", str(e))
            raise DashboardDatabaseError(
                "ì‚¬ìš©ì í™œë™ ë‚´ì—­ì„ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                operation="get_user_activities",
                table="user_activity_logs",
            ) from e
        except Exception as e:
            logger.error("ì‚¬ìš©ì í™œë™ ë‚´ì—­ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", str(e))
            raise DashboardServiceError(f"ì‚¬ìš©ì í™œë™ ë‚´ì—­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    # ============================================================================
    # ì´ë²¤íŠ¸ ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ============================================================================

    async def get_event_detail(self, user_id: UUID, event_id: str) -> Dict[str, Any]:
        """ì´ë²¤íŠ¸ ìƒì„¸ ì¡°íšŒ"""
        try:
            await self._verify_user_access(user_id)

            event_uuid = self._extract_uuid(event_id)
            if not event_uuid:
                raise DashboardValidationError(
                    "ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë²¤íŠ¸ IDì…ë‹ˆë‹¤",
                    field="event_id",
                    value=event_id,
                )

            query = (
                select(Event)
                .join(Calendar)
                .where(
                    and_(
                        Event.id == event_uuid,
                        Calendar.owner_id == user_id,
                    )
                )
            )
            result = await self.db.execute(query)
            event = result.scalar_one_or_none()

            if not event:
                raise DashboardDataNotFoundError(
                    "ì´ë²¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    resource_type="event",
                    resource_id=event_id,
                )

            return {
                "id": str(event.id),
                "title": event.title,
                "description": getattr(event, "description", ""),
                "type": "meeting",
                "priority": "medium",
                "start_time": event.start_time,
                "end_time": getattr(
                    event, "end_time", event.start_time + timedelta(hours=1)
                ),
                "location": getattr(event, "location", ""),
                "attendees": [],
                "project_id": None,
                "status": "confirmed",
                "created_by": str(user_id),
                "created_at": getattr(event, "created_at", event.start_time),
            }

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ì´ë²¤íŠ¸ ìƒì„¸ ì¡°íšŒ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: %s", str(e))
            raise DashboardDatabaseError(
                "ì´ë²¤íŠ¸ ìƒì„¸ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                operation="get_event_detail",
                table="events",
            ) from e
        except Exception as e:
            logger.error("ì´ë²¤íŠ¸ ìƒì„¸ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", str(e))
            raise DashboardServiceError(f"ì´ë²¤íŠ¸ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def get_user_events(
        self,
        current_user_id: UUID,
        target_user_id: str,
        page_size: int = 20,
        days: int = 7,
    ) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ìë³„ ì˜ˆì •ëœ ì´ë²¤íŠ¸ ì¡°íšŒ"""
        try:
            await self._verify_user_access(current_user_id)

            target_uuid = self._extract_uuid(target_user_id)
            if not target_uuid:
                raise DashboardValidationError(
                    "ìœ íš¨í•˜ì§€ ì•Šì€ ì‚¬ìš©ì IDì…ë‹ˆë‹¤",
                    field="target_user_id",
                    value=target_user_id,
                )

            # ê¶Œí•œ í™•ì¸ - ë³¸ì¸ì´ê±°ë‚˜ ê´€ë¦¬ìì¸ ê²½ìš°ë§Œ í—ˆìš©
            if current_user_id != target_uuid:
                raise DashboardPermissionError(
                    "ë‹¤ë¥¸ ì‚¬ìš©ìì˜ ì´ë²¤íŠ¸ë¥¼ ì¡°íšŒí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤",
                    required_permission="view_other_user_events",
                    user_id=str(current_user_id),
                )

            end_date = datetime.now(timezone.utc) + timedelta(days=days)

            query = (
                select(Event)
                .join(Calendar)
                .where(
                    and_(
                        Calendar.owner_id == target_uuid,
                        Event.start_time >= datetime.now(timezone.utc),
                        Event.start_time <= end_date,
                    )
                )
                .order_by(Event.start_time)
                .limit(page_size)
            )

            result = await self.db.execute(query)
            events = result.scalars().all()

            return [
                {
                    "id": str(event.id),
                    "title": event.title,
                    "description": getattr(event, "description", ""),
                    "type": "meeting",
                    "priority": "medium",
                    "start_time": event.start_time,
                    "end_time": getattr(
                        event, "end_time", event.start_time + timedelta(hours=1)
                    ),
                    "duration": 60,
                    "location": getattr(event, "location", ""),
                    "attendees": [],
                    "attendee_count": 0,
                    "project_id": None,
                    "project_name": None,
                    "is_recurring": False,
                    "reminder_set": False,
                    "calendar_name": "ê¸°ë³¸ ìº˜ë¦°ë”",
                    "status": "confirmed",
                }
                for event in events
            ]

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ì‚¬ìš©ì ì´ë²¤íŠ¸ ì¡°íšŒ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: %s", str(e))
            raise DashboardDatabaseError(
                "ì‚¬ìš©ì ì´ë²¤íŠ¸ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                operation="get_user_events",
                table="events",
            ) from e
        except Exception as e:
            logger.error("ì‚¬ìš©ì ì´ë²¤íŠ¸ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", str(e))
            raise DashboardServiceError(f"ì‚¬ìš©ì ì´ë²¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    # ============================================================================
    # ì„¤ì • ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ============================================================================

    async def update_dashboard_settings(
        self, user_id: UUID, settings: Dict[str, Any]
    ) -> None:
        """ëŒ€ì‹œë³´ë“œ ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            await self._verify_user_access(user_id)
            logger.info(
                "ëŒ€ì‹œë³´ë“œ ì„¤ì • ì—…ë°ì´íŠ¸: user_id=%s, settings=%s", user_id, settings
            )
            # ì‹¤ì œ êµ¬í˜„ ì‹œ ì‚¬ìš©ì ì„¤ì • í…Œì´ë¸”ì— ì €ì¥
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}") from e

    async def get_dashboard_settings(self, user_id: UUID) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ì„¤ì • ì¡°íšŒ"""
        try:
            await self._verify_user_access(user_id)
            return {
                "layout": {"columns": 2, "responsive": True},
                "widgets": [],
                "preferences": {"theme": "light", "auto_refresh": True},
                "theme": "light",
                "notifications": {"email": True, "push": False},
                "auto_refresh": True,
                "refresh_interval": 30,
            }
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def reset_dashboard_settings(self, user_id: UUID) -> None:
        """ëŒ€ì‹œë³´ë“œ ì„¤ì • ì´ˆê¸°í™”"""
        try:
            await self._verify_user_access(user_id)
            logger.info("ëŒ€ì‹œë³´ë“œ ì„¤ì • ì´ˆê¸°í™”: user_id=%s", user_id)
            # ì‹¤ì œ êµ¬í˜„ ì‹œ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë¦¬ì…‹
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}") from e

    # ============================================================================
    # ë°ì´í„° ë‚´ë³´ë‚´ê¸° ë©”ì„œë“œë“¤
    # ============================================================================

    async def export_dashboard_data(
        self,
        user_id: UUID,
        export_format: str,
    ) -> tuple:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë‚´ë³´ë‚´ê¸° (ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ)"""
        try:
            await self._verify_user_access(user_id)

            # ë°ì´í„° ìˆ˜ì§‘
            stats = await self.get_user_summary(user_id)

            if export_format == "json":
                content = StringIO(json.dumps(stats, default=str, indent=2))
                filename = (
                    f"dashboard_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                )
                media_type = "application/json"
            elif export_format == "csv":
                content = StringIO()
                writer = csv.writer(content)
                writer.writerow(["Metric", "Value"])
                for key, value in stats.items():
                    writer.writerow([key, str(value)])
                content.seek(0)
                filename = (
                    f"dashboard_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                )
                media_type = "text/csv"
            else:
                raise DashboardValidationError(
                    f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ë³´ë‚´ê¸° í˜•ì‹: {format}",
                    field="format",
                    value=format,
                )

            return content, filename, media_type

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardExportError(
                f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}",
                export_format=export_format,
            ) from e

    async def start_async_export(
        self,
        user_id: UUID,
        export_format: str,
    ) -> str:
        """ë¹„ë™ê¸° ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹œì‘"""
        try:
            await self._verify_user_access(user_id)

            # UUID ìƒì„±í•˜ì—¬ ë‚´ë³´ë‚´ê¸° IDë¡œ ì‚¬ìš©

            export_id = str(uuid4())

            logger.info(
                "ë¹„ë™ê¸° ë‚´ë³´ë‚´ê¸° ì‹œì‘: export_id=%s, user_id=%s", export_id, user_id
            )
            # ì‹¤ì œ êµ¬í˜„ ì‹œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì²˜ë¦¬

            return export_id

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardExportError(
                f"ë¹„ë™ê¸° ë‚´ë³´ë‚´ê¸° ì‹œì‘ ì‹¤íŒ¨: {str(e)}",
                export_format=export_format,
            ) from e

    async def get_export_status(self, user_id: UUID, export_id: str) -> Dict[str, Any]:
        """ë‚´ë³´ë‚´ê¸° ìƒíƒœ í™•ì¸"""
        try:
            await self._verify_user_access(user_id)

            return {
                "status": "completed",
                "progress": 100.0,
                "download_url": f"/api/dashboard/export/{export_id}/download",
                "expires_at": datetime.now(timezone.utc) + timedelta(hours=24),
                "error_message": None,
                "created_at": datetime.now(timezone.utc),
            }

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardExportError(
                f"ë‚´ë³´ë‚´ê¸° ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}",
                export_id=export_id,
            ) from e

    async def download_export(self, user_id: UUID, export_id: str) -> tuple:
        """ë‚´ë³´ë‚¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            await self._verify_user_access(user_id)

            # ì„ì‹œë¡œ JSON ë°ì´í„° ë°˜í™˜
            stats = await self.get_user_summary(user_id)

            content = StringIO(json.dumps(stats, default=str, indent=2))
            filename = f"export_{export_id}.json"
            media_type = "application/json"

            return content, filename, media_type

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardExportError(
                f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}",
                export_id=export_id,
            ) from e

    # ============================================================================
    # ìºì‹œ ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ============================================================================

    async def invalidate_cache(self, user_id: UUID) -> None:
        """ëŒ€ì‹œë³´ë“œ ìºì‹œ ë¬´íš¨í™”"""
        try:
            await self._verify_user_access(user_id)
            logger.info("ìºì‹œ ë¬´íš¨í™”: user_id=%s", user_id)
            # ì‹¤ì œ êµ¬í˜„ ì‹œ Redis ë“±ì˜ ìºì‹œ ë¬´íš¨í™”
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardCacheError(
                f"ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {str(e)}",
                operation="invalidate_all",
            ) from e

    async def invalidate_specific_cache(
        self, user_id: UUID, cache_keys: List[str]
    ) -> None:
        """íŠ¹ì • ë°ì´í„° ìºì‹œ ë¬´íš¨í™”"""
        try:
            await self._verify_user_access(user_id)
            logger.info("íŠ¹ì • ìºì‹œ ë¬´íš¨í™”: user_id=%s, keys=%s", user_id, cache_keys)
            # ì‹¤ì œ êµ¬í˜„ ì‹œ ì§€ì •ëœ í‚¤ë“¤ë§Œ ë¬´íš¨í™”
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardCacheError(
                f"íŠ¹ì • ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {str(e)}",
                operation="invalidate_specific",
            ) from e

    async def get_cache_status(self, user_id: UUID) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ì¡°íšŒ"""
        try:
            await self._verify_user_access(user_id)

            return {
                "total_keys": 150,
                "memory_usage": 25.6,
                "hit_rate": 85.2,
                "last_cleanup": datetime.now(timezone.utc) - timedelta(hours=1),
                "cache_size": 26843545,
            }

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardCacheError(
                f"ìºì‹œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                operation="get_status",
            ) from e

    # ============================================================================
    # ì•Œë¦¼ ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ============================================================================

    async def get_notifications(
        self,
        user_id: UUID,
        page_size: int = 20,
        page_no: int = 1,
        unread_only: bool = False,
    ) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ì•Œë¦¼ ì¡°íšŒ"""
        try:
            await self._verify_user_access(user_id)

            # ì„ì‹œ ì•Œë¦¼ ë°ì´í„°
            notifications = [
                {
                    "id": f"notif_{i}",
                    "title": f"ì•Œë¦¼ {i}",
                    "message": f"ì•Œë¦¼ ë©”ì‹œì§€ {i}",
                    "type": "info",
                    "priority": "normal",
                    "read_at": None if i % 2 == 0 else datetime.now(timezone.utc),
                    "action_url": None,
                    "created_at": datetime.now(timezone.utc) - timedelta(hours=i),
                }
                for i in range(1, min(page_size + 1, 11))
            ]

            if unread_only:
                notifications = [n for n in notifications if n["read_at"] is None]

            total = len(notifications)
            unread_count = len([n for n in notifications if n["read_at"] is None])
            total_pages = (total + page_size - 1) // page_size

            return {
                "notifications": notifications,
                "total": total,
                "unread_count": unread_count,
                "page_no": page_no,
                "page_size": page_size,
                "total_pages": total_pages,
            }

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì•Œë¦¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def mark_notification_as_read(
        self, user_id: UUID, notification_id: str
    ) -> None:
        """ì•Œë¦¼ ì½ìŒ ì²˜ë¦¬"""
        try:
            await self._verify_user_access(user_id)
            logger.info(
                "ì•Œë¦¼ ì½ìŒ ì²˜ë¦¬: user_id=%s, notification_id=%s",
                user_id,
                notification_id,
            )
            # ì‹¤ì œ êµ¬í˜„ ì‹œ ì•Œë¦¼ í…Œì´ë¸” ì—…ë°ì´íŠ¸
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì•Œë¦¼ ì½ìŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}") from e

    async def mark_all_notifications_as_read(self, user_id: UUID) -> None:
        """ëª¨ë“  ì•Œë¦¼ ì½ìŒ ì²˜ë¦¬"""
        try:
            await self._verify_user_access(user_id)
            logger.info("ëª¨ë“  ì•Œë¦¼ ì½ìŒ ì²˜ë¦¬: user_id=%s", user_id)
            # ì‹¤ì œ êµ¬í˜„ ì‹œ ëª¨ë“  ì•Œë¦¼ ì½ìŒ ì²˜ë¦¬
        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ëª¨ë“  ì•Œë¦¼ ì½ìŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}") from e

    # ============================================================================
    # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë©”ì„œë“œë“¤
    # ============================================================================

    async def check_for_updates(
        self, user_id: UUID, last_update: Optional[str] = None
    ) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸ í™•ì¸"""
        try:
            await self._verify_user_access(user_id)

            last_update_time = datetime.now(timezone.utc) - timedelta(minutes=5)
            if last_update:
                try:
                    last_update_time = datetime.fromisoformat(
                        last_update.replace("Z", "+00:00")
                    )
                except ValueError:
                    pass

            current_time = datetime.now(timezone.utc)
            has_updates = current_time > last_update_time

            return {
                "has_updates": has_updates,
                "last_updated": current_time,
                "updated_sections": ["stats", "activities"] if has_updates else [],
                "next_check": current_time + timedelta(minutes=5),
            }

        except Exception as e:
            if isinstance(e, DashboardServiceError):
                raise
            raise DashboardServiceError(f"ì—…ë°ì´íŠ¸ í™•ì¸ ì‹¤íŒ¨: {str(e)}") from e

    # ============================================================================
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë©”ì„œë“œë“¤
    # ============================================================================

    async def get_performance_metrics(self, user_id: UUID) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        try:
            start_time = time.time()

            await self._verify_user_access(user_id)

            # ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ ì‹œê°„ ê¸°ë¡
            query_start_time = time.time()

            # 1. ìµœê·¼ 24ì‹œê°„ ë‚´ í™œì„± ì‚¬ìš©ì ìˆ˜ ì¡°íšŒ
            yesterday = datetime.now(timezone.utc) - timedelta(days=1)
            active_users_query = text("""
                SELECT COUNT(DISTINCT user_id) as active_users
                FROM user_activity_logs
                WHERE created_at >= :yesterday
            """)
            active_users_result = await self.db.execute(
                active_users_query, {"yesterday": yesterday}
            )
            active_users = active_users_result.scalar() or 0

            # 2. ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • (í‰ê·  ì‘ë‹µì‹œê°„)
            db_performance_query = text("""
                SELECT
                    AVG(EXTRACT(EPOCH FROM (NOW() - query_start))) as avg_query_time
                FROM pg_stat_activity
                WHERE state = 'active'
                  AND query_start IS NOT NULL
                  AND query != '<IDLE>'
                LIMIT 100
            """)
            try:
                db_performance_result = await self.db.execute(db_performance_query)
                avg_query_time = db_performance_result.scalar() or 0.0
                if avg_query_time is None:
                    avg_query_time = 0.0
            except Exception:
                # PostgreSQL stat ì ‘ê·¼ ê¶Œí•œì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                avg_query_time = 0.15

            # 3. ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚° (PostgreSQL ë²„í¼ ìºì‹œ ê¸°ì¤€)
            cache_hit_query = text("""
                SELECT
                    CASE
                        WHEN (blks_hit + blks_read) = 0 THEN 0
                        ELSE ROUND((blks_hit::float / (blks_hit + blks_read)) * 100, 2)
                    END as cache_hit_rate
                FROM pg_stat_database
                WHERE database_name = current_database()
            """)
            try:
                cache_hit_result = await self.db.execute(cache_hit_query)
                cache_hit_rate = cache_hit_result.scalar() or 0.0
            except Exception:
                # ê¶Œí•œì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
                cache_hit_rate = 85.0

            # 4. ì‚¬ìš©ìë³„ ìµœê·¼ í™œë™ëŸ‰ ê¸°ë°˜ ë¶€í•˜ ì¸¡ì •
            user_load_query = text("""
                SELECT COUNT(*) as recent_activities
                FROM user_activity_logs
                WHERE user_id = :user_id
                  AND created_at >= :recent_time
            """)
            recent_time = datetime.now(timezone.utc) - timedelta(minutes=30)
            user_load_result = await self.db.execute(
                user_load_query, {"user_id": user_id, "recent_time": recent_time}
            )
            recent_activities = user_load_result.scalar() or 0

            # 5. ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                memory_info = psutil.virtual_memory()
                memory_usage_mb = memory_info.used / 1024 / 1024
                memory_usage_percent = memory_info.percent
            except Exception:
                # psutil ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ê¸°ë³¸ê°’
                memory_usage_mb = 256.0
                memory_usage_percent = 65.0

            # 6. ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            query_end_time = time.time()
            query_time = round((query_end_time - query_start_time) * 1000, 2)  # ms

            # 7. í˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì¶”ì • (ì¿¼ë¦¬ ì‹œê°„ + ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ)
            estimated_load_time = query_time + 200  # ê¸°ë³¸ ì˜¤ë²„í—¤ë“œ 200ms
            load_time_seconds = round(estimated_load_time / 1000, 3)

            end_time = time.time()
            total_processing_time = round((end_time - start_time) * 1000, 2)

            return {
                "load_time": load_time_seconds,
                "query_time": round(avg_query_time, 3),
                "cache_hit_rate": float(cache_hit_rate),
                "active_users": active_users,
                "memory_usage": round(memory_usage_mb, 1),
                "memory_usage_percent": round(memory_usage_percent, 1),
                "recent_user_activities": recent_activities,
                "processing_time_ms": total_processing_time,
                "database_connections": await self._get_active_connections(),
                "performance_score": await self._calculate_performance_score(
                    load_time_seconds, cache_hit_rate, memory_usage_percent
                ),
                "measured_at": datetime.now(timezone.utc),
            }

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ - ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ: %s", str(e))
            raise DashboardDatabaseError(
                f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ë¡œ ì¸í•œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                operation="get_performance_metrics",
                table="multiple",
            ) from e
        except Exception as e:
            logger.error("ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: user_id=%s, error=%s", user_id, str(e))
            raise DashboardServiceError(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e

    async def _get_active_connections(self) -> int:
        """í™œì„± ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìˆ˜ ì¡°íšŒ"""
        try:
            connections_query = text("""
                SELECT COUNT(*) as active_connections
                FROM pg_stat_activity
                WHERE state = 'active'
            """)
            result = await self.db.execute(connections_query)
            return result.scalar() or 0
        except Exception:
            return 0

    async def _calculate_performance_score(
        self, load_time: float, cache_hit_rate: float, memory_usage_percent: float
    ) -> float:
        """ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (0-100)"""
        try:
            # ë¡œë“œ ì‹œê°„ ì ìˆ˜ (1ì´ˆ ì´í•˜ë©´ 100ì , 3ì´ˆ ì´ìƒì´ë©´ 0ì )
            load_score = max(0, 100 - (load_time - 1.0) * 50)

            # ìºì‹œ íˆíŠ¸ìœ¨ ì ìˆ˜ (90% ì´ìƒì´ë©´ 100ì )
            cache_score = min(100, cache_hit_rate * 1.1)

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì ìˆ˜ (70% ì´í•˜ë©´ 100ì , 90% ì´ìƒì´ë©´ 0ì )
            memory_score = max(0, 100 - max(0, memory_usage_percent - 70) * 5)

            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
            performance_score = (
                load_score * 0.4 + cache_score * 0.3 + memory_score * 0.3
            )

            return round(performance_score, 1)
        except Exception:
            return 50.0  # ê¸°ë³¸ ì ìˆ˜

    async def get_activity_metrics(
        self, user_id: UUID, period: str = "7d"
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì í™œë™ í†µê³„ ì¡°íšŒ"""
        try:
            await self._verify_user_access(user_id)

            # ê¸°ê°„ íŒŒì‹±
            period_delta = self._parse_period(period)
            start_date = datetime.now(timezone.utc) - period_delta

            # ì‚¬ìš©ìê°€ ì ‘ê·¼ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ ì¡°íšŒ
            project_ids = await self._get_user_project_ids(user_id)

            if not project_ids:
                return {
                    "total_activities": 0,
                    "unique_users": 0,
                    "most_active_users": [],
                    "activity_by_hour": [{"hour": i, "count": 0} for i in range(24)],
                    "activity_by_type": {
                        "create": 0,
                        "update": 0,
                        "delete": 0,
                        "view": 0,
                    },
                }

            # ì „ì²´ í™œë™ ìˆ˜ ì¡°íšŒ
            total_activities_query = select(count(UserActivityLog.id)).where(
                and_(
                    UserActivityLog.user_id == user_id,
                    UserActivityLog.created_at >= start_date,
                )
            )
            total_result = await self.db.execute(total_activities_query)
            total_activities = total_result.scalar() or 0

            # ê´€ë ¨ í”„ë¡œì íŠ¸ì˜ ê³ ìœ  ì‚¬ìš©ì ìˆ˜ ì¡°íšŒ (í”„ë¡œì íŠ¸ ë©¤ë²„ë“¤ì˜ í™œë™)
            unique_users_query = text("""
                SELECT COUNT(DISTINCT ual.user_id)
                FROM user_activity_logs ual
                WHERE ual.created_at >= :start_date
                  AND (
                    ual.user_id = :user_id
                    OR ual.resource_id::text IN (
                      SELECT p.id::text FROM projects p WHERE p.id = ANY(:project_ids)
                    )
                  )
            """)
            unique_users_result = await self.db.execute(
                unique_users_query,
                {
                    "start_date": start_date,
                    "user_id": user_id,
                    "project_ids": project_ids,
                },
            )
            unique_users = unique_users_result.scalar() or 0

            # ê°€ì¥ í™œë°œí•œ ì‚¬ìš©ìë“¤ ì¡°íšŒ (ê´€ë ¨ í”„ë¡œì íŠ¸ ê¸°ì¤€)
            most_active_query = text("""
                SELECT ual.user_id, COUNT(ual.id) as activity_count
                FROM user_activity_logs ual
                WHERE ual.created_at >= :start_date
                  AND (
                    ual.user_id = :user_id
                    OR ual.resource_id::text IN (
                      SELECT p.id::text FROM projects p WHERE p.id = ANY(:project_ids)
                    )
                  )
                GROUP BY ual.user_id
                ORDER BY activity_count DESC
                LIMIT 5
            """)
            most_active_result = await self.db.execute(
                most_active_query,
                {
                    "start_date": start_date,
                    "user_id": user_id,
                    "project_ids": project_ids,
                },
            )
            most_active_users = [
                {"user_id": str(row[0]), "activity_count": row[1]}
                for row in most_active_result.fetchall()
            ]

            # ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„í¬ ì¡°íšŒ
            activity_by_hour_query = text("""
                SELECT EXTRACT(HOUR FROM ual.created_at) as hour, COUNT(ual.id) as count
                FROM user_activity_logs ual
                WHERE ual.user_id = :user_id
                  AND ual.created_at >= :start_date
                GROUP BY EXTRACT(HOUR FROM ual.created_at)
                ORDER BY hour
            """)
            hour_result = await self.db.execute(
                activity_by_hour_query, {"user_id": user_id, "start_date": start_date}
            )
            hour_data = {int(row[0]): row[1] for row in hour_result.fetchall()}

            activity_by_hour = [
                {"hour": i, "count": hour_data.get(i, 0)} for i in range(24)
            ]

            # í™œë™ ìœ í˜•ë³„ ë¶„í¬ ì¡°íšŒ
            activity_by_type_query = text("""
                SELECT
                    CASE
                        WHEN ual.action ILIKE '%create%' OR ual.action ILIKE '%add%' THEN 'create'
                        WHEN ual.action ILIKE '%update%' OR ual.action ILIKE '%edit%' OR ual.action ILIKE '%modify%' THEN 'update'
                        WHEN ual.action ILIKE '%delete%' OR ual.action ILIKE '%remove%' THEN 'delete'
                        WHEN ual.action ILIKE '%view%' OR ual.action ILIKE '%read%' OR ual.action ILIKE '%access%' THEN 'view'
                        ELSE 'other'
                    END as action_type,
                    COUNT(ual.id) as count
                FROM user_activity_logs ual
                WHERE ual.user_id = :user_id
                  AND ual.created_at >= :start_date
                GROUP BY action_type
            """)
            type_result = await self.db.execute(
                activity_by_type_query, {"user_id": user_id, "start_date": start_date}
            )
            type_data = {row[0]: row[1] for row in type_result.fetchall()}

            activity_by_type = {
                "create": type_data.get("create", 0),
                "update": type_data.get("update", 0),
                "delete": type_data.get("delete", 0),
                "view": type_data.get("view", 0),
                "other": type_data.get("other", 0),
            }

            return {
                "total_activities": total_activities,
                "unique_users": unique_users,
                "most_active_users": most_active_users,
                "activity_by_hour": activity_by_hour,
                "activity_by_type": activity_by_type,
                "period": period,
                "start_date": start_date,
                "end_date": datetime.now(timezone.utc),
            }

        except (
            DashboardDataNotFoundError,
            DashboardPermissionError,
            DashboardValidationError,
        ):
            raise
        except SQLAlchemyError as e:
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ - í™œë™ ë©”íŠ¸ë¦­ ì¡°íšŒ: %s", str(e))
            raise DashboardDatabaseError(
                f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ë¡œ ì¸í•œ í™œë™ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                operation="get_activity_metrics",
                table="user_activity_logs",
            ) from e
        except Exception as e:
            logger.error("í™œë™ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: user_id=%s, error=%s", user_id, str(e))
            raise DashboardServiceError(f"í™œë™ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}") from e


async def get_dashboard_service(
    db: Optional[AsyncSession] = None,
) -> DashboardService:
    """ëŒ€ì‹œë³´ë“œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    if db is None:
        async for session in get_async_session():
            return DashboardService(session)
    return DashboardService(cast(AsyncSession, db))
